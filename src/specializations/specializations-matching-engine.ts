export interface WordSynonym {
    src: string;
    dst: string | null;
}

export interface WordWeight {
    word: string;
    weight: number;
}

export class SpecializationsMatchingEngine {
    private synonyms: Map<string, string | null>;
    private weights: Map<string, number>;
    private normalizedSpecs: { original: string; words: string[] }[];
    private localSynonyms: Map<string, string>;
    private stopWords: Set<string>;

    constructor(
        specializationNames: string[],
        synonyms: WordSynonym[],
        weights: WordWeight[]
    ) {
        this.synonyms = new Map();
        for (const s of synonyms) {
            this.synonyms.set(this.replaceHomoglyphs(s.src.toLowerCase()), s.dst ? s.dst.toLowerCase() : null);
        }

        // 1. Initialize local synonyms with homoglyphs replaced in keys
        this.localSynonyms = new Map();
        const rawLocal: Record<string, string> = {
            'uxui': 'Ð´Ð¸Ð·Ð°Ð¹Ð½ÐµÑ€',
            'ux': 'Ð´Ð¸Ð·Ð°Ð¹Ð½ÐµÑ€',
            'ui': 'Ð´Ð¸Ð·Ð°Ð¹Ð½ÐµÑ€',
            'sa': 'ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº',
            'ba': 'Ð±Ð¸Ð·Ð½ÐµÑ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº',
            'ÑÐ°': 'ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº',
            'Ð±Ð°': 'Ð±Ð¸Ð·Ð½ÐµÑ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº',
            'be': 'backend',
            'fe': 'frontend',
            'do': 'devops',
            'qa': 'Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº',
            'developer': 'Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº',
            'engineer': 'Ð¸Ð½Ð¶ÐµÐ½ÐµÑ€',
            'analyst': 'Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ðº',
            'scrum': 'ÑÐºÑ€Ð°Ð¼',
            'master': 'Ð¼Ð°ÑÑ‚ÐµÑ€',
            'backend': 'Ð±ÑÐºÐµÐ½Ð´',
            'frontend': 'Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´',
            'fullstack': 'Ñ„ÑƒÐ»Ð»ÑÑ‚ÐµÐº',
            'mobile': 'Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹',
            'ios': 'Ð¸Ð¾Ñ',
            'android': 'Ð°Ð½Ð´Ñ€Ð¾Ð¸Ð´',
            'scientist': 'ÑÐ°Ð¹ÐµÐ½Ñ‚Ð¸ÑÑ‚',
            'data': 'Ð´Ð°Ñ‚Ð°',
            'architect': 'Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚Ð¾Ñ€',
            'lead': 'Ð»Ð¸Ð´',
            'manager': 'Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€',
            'owner': 'Ð¾Ð²Ð½ÐµÑ€',
            'Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ': 'Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ñ‰Ð¸Ðº',
            'Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ð¾Ðµ': 'Ð½Ð°Ð³Ñ€ÑƒÐ·Ð¾Ñ‡Ð½Ñ‹Ð¹',
            'Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ': 'Ñ€ÑƒÑ‡Ð½Ð¾Ð¹',
            'Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸': 'Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº',
            'Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚': 'Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº',
        };
        for (const [k, v] of Object.entries(rawLocal)) {
            this.localSynonyms.set(this.replaceHomoglyphs(k.toLowerCase()), v);
        }

        // 2. Initialize weights
        this.weights = new Map();
        for (const w of weights) {
            const words = this.normalize(w.word).split(/\s+/).filter(tk => tk.length > 0);
            for (const token of words) {
                this.weights.set(token, w.weight);
            }
        }

        // 3. Initialize stopwords
        const rawStop = [
            'Ð²', 'Ð½Ð°', 'Ñ', 'Ðº', 'Ð¿Ð¾', 'Ð¸Ð·', 'Ð¾Ñ‚', 'Ð´Ð¾', 'Ñƒ', 'Ð¾', 'Ð¾Ð±', 'Ð·Ð°', 'Ð½Ð°Ð´', 'Ð¿Ð¾Ð´', 'Ð¿Ñ€Ð¸', 'Ð´Ð»Ñ',
            'Ð¸', 'Ð°', 'Ð½Ð¾', 'Ð´Ð°', 'Ð¸Ð»Ð¸', 'ÐºÐ°Ðº', 'Ñ‚Ð°Ðº', 'Ñ‡Ñ‚Ð¾', 'Ñ‡Ñ‚Ð¾Ð±Ñ‹', 'ÐµÑÐ»Ð¸', 'Ñ…Ð¾Ñ‚Ñ', 'Ð½Ðµ', 'Ð½Ð¸', 'Ð¶Ðµ', 'Ð»Ð¸',
            'senior', 'middle', 'junior', 'lead', 'tech', 'team', 'lead', 'senior+', 'middle+', 'junior+',
            'ðŸ†”', 'redlab', 'mts', 'digital', 'Ð¼Ñ‚Ñ', 'Ð´Ð¸Ð´Ð¶Ð¸Ñ‚Ð°Ð»', 'Ð»ÐµÐ¼Ð°Ð½Ð°Ð¿Ñ€Ð¾', 'x5', 'Ð²Ðº', 'vk', 'ÐºÑ€Ð¾Ðº', 'itfb',
            'the', 'a', 'an', 'of', 'for', 'to', 'in', 'on', 'at', 'by', 'with', 'Ð¿Ñ€Ð¾ÐµÐºÑ‚', 'Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°', 'Ð¿Ñ€Ð¾ÐµÐºÑ‚Ðµ',
            'Ð½Ð¾Ð¼ÐµÑ€', 'Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð½Ð¾ÑÑ‚Ð¸', 'id', 'Ð¿2026', 'ðŸ†”', 'ÐºÐ¾Ð»Ð»ÐµÐ³Ð¸', 'Ð²ÑÐµÐ¼', 'Ð¿Ñ€Ð¸Ð²ÐµÑ‚', 'Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ', 'Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð½Ð¾ÑÑ‚Ð¸',
        ];
        this.stopWords = new Set(rawStop.map(w => this.replaceHomoglyphs(w.toLowerCase())));

        // 4. Pre-normalize specializations
        this.normalizedSpecs = specializationNames.map(name => {
            const normalized = this.normalize(name);
            return {
                original: name,
                words: normalized.split(/\s+/).filter(w => !this.stopWords.has(w) && w.length >= 2)
            };
        });
    }

    public normalize(text: string): string {
        let result = text.toLowerCase();

        // MUST be before homoglyph replacement
        result = result.replace(/front[-\s]+end/g, 'frontend');
        result = result.replace(/back[-\s]+end/g, 'backend');
        result = result.replace(/full[-\s]+stack/g, 'fullstack');
        result = result.replace(/ux[-\s]*ui/g, 'uxui');
        result = result.replace(/ui[-\s]*ux/g, 'uxui');

        result = this.replaceHomoglyphs(result);
        result = result.replace(/Ð´wh/g, 'dwh');

        result = result.replace(/[^a-zÐ°-Ñ0-9]/gi, ' ');

        const words = result.split(/\s+/).filter(w => w.length > 0);

        const normalizedWords = words.map(w => {
            let current = w;

            // Global synonym
            if (this.synonyms && this.synonyms.has(current)) {
                current = this.synonyms.get(current) || '';
            }

            // Local common IT synonym
            if (this.localSynonyms.has(current)) {
                current = this.localSynonyms.get(current)!;
            }

            return current;
        }).filter(w => w.length > 0);

        return normalizedWords.join(' ').trim();
    }

    private replaceHomoglyphs(text: string): string {
        const map: Record<string, string> = {
            'a': 'Ð°', 'c': 'Ñ', 'e': 'Ðµ', 'o': 'Ð¾', 'p': 'Ñ€', 'x': 'Ñ…', 'y': 'Ñƒ'
        };
        return text.replace(/[aceopxy]/g, m => map[m]!);
    }

    public weightedCoverageRatio(specWords: string[], textWords: string[]): number {
        if (specWords.length === 0 || textWords.length === 0) return 0;

        let specTotalWeight = 0;
        let textTotalWeight = 0;
        let matchedWeight = 0;

        const specSet = new Set(specWords);
        const textSet = new Set(textWords);

        const isMarker = (w: string) => /^\d+$/.test(w) || /^Ð¿\d+$/i.test(w) || (w.length > 5 && /\d/.test(w));

        const getWeight = (word: string) => {
            const lookup = this.replaceHomoglyphs(word.toLowerCase());
            return this.weights.get(lookup) || 1.0;
        };

        for (const word of specSet) {
            if (this.stopWords.has(word) || isMarker(word) || word.length < 2) continue;
            const weight = getWeight(word);
            specTotalWeight += weight;
            if (textSet.has(word)) matchedWeight += weight;
        }

        for (const word of textSet) {
            if (this.stopWords.has(word) || isMarker(word) || word.length < 2) continue;
            textTotalWeight += getWeight(word);
        }

        if (specTotalWeight === 0) return 0;
        return matchedWeight / Math.max(specTotalWeight, textTotalWeight);
    }

    public match(text: string): { specialization: string; score: number } | null {
        const normalizedText = this.normalize(text);
        const textWords = normalizedText.split(/\s+/).filter(w => w.length > 0);
        const filteredTextWords = textWords.filter(w => !this.stopWords.has(w) && w.length >= 2);

        let bestMatch: { specialization: string; score: number } | null = null;

        for (const spec of this.normalizedSpecs) {
            const score = this.weightedCoverageRatio(spec.words, filteredTextWords);

            if (score >= 0.25 && (!bestMatch || score > bestMatch.score)) {
                bestMatch = { specialization: spec.original, score };
            }
        }

        return bestMatch;
    }
}
